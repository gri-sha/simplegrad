{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e169edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p datasets\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O datasets/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplegrad as sg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fd7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BLOCK_SIZE = 8\n",
    "LEARNING_RATE = 1e-2\n",
    "MAX_ITERS = 3000\n",
    "VAL_INTERVAL = 300\n",
    "VAL_ITERS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a60b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab. size: 65\n"
     ]
    }
   ],
   "source": [
    "with open(\"datasets/shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(\"Vocab. size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a22759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i = {ch: i for i, ch in enumerate(chars)}\n",
    "i2s = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda string: [s2i[ch] for ch in string]\n",
    "decode = lambda tokens: [i2s[tok] for tok in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae80a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1003854\n",
      "Val.: 111540\n"
     ]
    }
   ],
   "source": [
    "data = encode(text)\n",
    "split_idx = int(len(data) * 0.9)\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "print(\"Train:\", len(train_data))\n",
    "print(\"Val.:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06962c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(sg.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_table = sg.nn.Embedding(self.vocab_size, self.vocab_size)\n",
    "\n",
    "    def forward(self, context):\n",
    "        return self.embedding_table(context)\n",
    "\n",
    "    def generate(self, context, max_new_tokens=300):\n",
    "        res = [context.values.item()]\n",
    "        current = context\n",
    "        for _ in range(max_new_tokens):\n",
    "            next = sg.Tensor(\n",
    "                np.random.choice(range(self.vocab_size), size=1, p=sg.softmax(self.forward(current), dim=-1).values[0, 0, :]), dtype=\"int8\"\n",
    "            )\n",
    "            res.append(int(next.values.item()))\n",
    "            current = next\n",
    "        return res\n",
    "\n",
    "\n",
    "model = BigramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72eb1a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_example: (32, 8)\n",
      "y_example: (32, 8, 65)\n"
     ]
    }
   ],
   "source": [
    "def get_batches(split=\"train\"):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    idxs = np.random.randint(low=0, high=len(data) - BLOCK_SIZE, size=(BATCH_SIZE,))\n",
    "    x = sg.Tensor([data[i : i + BLOCK_SIZE] for i in idxs], dtype=\"int8\")\n",
    "    y = [data[i + 1 : i + BLOCK_SIZE + 1] for i in idxs]\n",
    "    y_one_hot = sg.zeros((BATCH_SIZE, BLOCK_SIZE, vocab_size), comp_grad=False)\n",
    "    for b in range(BATCH_SIZE):\n",
    "        for t in range(BLOCK_SIZE):\n",
    "            y_one_hot.values[b, t, y[b][t]] = 1\n",
    "    return x, y_one_hot\n",
    "\n",
    "\n",
    "x_example, y_example = get_batches(\"train\")\n",
    "print(\"x_example:\", x_example.shape)\n",
    "print(\"y_example:\", y_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c527cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss():\n",
    "    out = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = np.zeros(VAL_ITERS)\n",
    "        for i in range(VAL_ITERS):\n",
    "            x_batch, y_batch = get_batches(split)\n",
    "            losses[i] = sg.ce_loss(model(x_batch), y_batch).values.item()\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6712ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T$W,-.s-gDLYHiHT3?jcAig cb3nXUXRC:$mK:?glmz,.yUTPAbJJ,:WXyFOG&F.riHTmLAQ.q!XvaBI'RUA?!Yyb-End,- EB'N?ug$$;T IRC\n",
      "px$UXEBVBHuO3EES-lxsj$p- .Xp-a;&\n",
      "nCxdK-hFJOxtuV$;upnma''3ipYQ'k!&\n",
      "lrcimW,C\n",
      "nW.H3p-A.COzlefKkNpEDQncTnf?Te,3lgG:\n",
      "DzVQy-cARrwaq-DFLbZ oTPslHrG!GQPjiQjzbJSGIO-lJn$WflRrQDIUoMwQOp.:y:-sjTPoupgSJF.yWeNwexexeTSkARY&.:KvluVoMOzGTj&vYBZHY,MPcAiQ.;Ovuvvaxmejgx&O?xPvm$m?als $W&\n",
      "VFhYwZ!jnBs:pGXj$qUXDFIhC$JoMhyO\n",
      "n,-ljXHLmt?jJGq!3O\n",
      "xZe?wJnmWHSaUsK:?dpEEoMwBBaDgpEWch,qE$QU?zGP'3:OWt!3&zPn pmW:H.YUT,t\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(decode(model.generate(context=sg.Tensor(s2i[\"T\"], dtype=\"int8\"), max_new_tokens=500))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9aeed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': np.float64(4.612938895225525), 'val': np.float64(4.626659710407257)}\n",
      "{'train': np.float64(2.8013719630241396), 'val': np.float64(2.8241304922103883)}\n",
      "{'train': np.float64(2.5444876492023467), 'val': np.float64(2.566481821537018)}\n",
      "{'train': np.float64(2.493301900625229), 'val': np.float64(2.510030850172043)}\n",
      "{'train': np.float64(2.476245114803314), 'val': np.float64(2.5081604492664336)}\n",
      "{'train': np.float64(2.468981717824936), 'val': np.float64(2.4957055079936983)}\n",
      "{'train': np.float64(2.470393862724304), 'val': np.float64(2.505697947740555)}\n",
      "{'train': np.float64(2.4662603878974916), 'val': np.float64(2.4936233174800875)}\n",
      "{'train': np.float64(2.4572763764858245), 'val': np.float64(2.4846458768844606)}\n",
      "{'train': np.float64(2.4568127751350404), 'val': np.float64(2.4850762152671813)}\n"
     ]
    }
   ],
   "source": [
    "optimizer = sg.opt.Adam(model, lr=LEARNING_RATE)\n",
    "\n",
    "for i in range(MAX_ITERS):\n",
    "    if i % VAL_INTERVAL == 0:\n",
    "        eval_loss = estimate_loss()\n",
    "        print(eval_loss)\n",
    "    x_batch, y_batch = get_batches()\n",
    "    loss = sg.ce_loss(model(x_batch), y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865f208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thyoldie wh gonk wathy fe d nillaridudamof; wille, cay ico lullatheane house V:\n",
      "We mont wand d CIUKI G mmef be seds n t oo e,\n",
      "WBy y ll bey s; n orde D m t g rmbucl!\n",
      "And soreay bosw BE:\n",
      "Whit wieised d ltot, hme re le:\n",
      "\n",
      "SooullfisunQUCl ESind in; y tre:\n",
      "Yes myo hthoras sy'tang t mys me, u mu:\n",
      "Go s y merissalllcimy-whos wit no;\n",
      "T:\n",
      "The'd brybl, me, ton ure HABealoue; t he gh thacel whaure: ben mex plfe ctome e?\n",
      "t erecrod nonomary ho sather, am:\n",
      "T: Vealyoutharheshe sthef pe st scout thour wit\n",
      "Havis win\n"
     ]
    }
   ],
   "source": [
    "print(''.join(decode(model.generate(context=sg.Tensor(s2i[\"T\"], dtype=\"int8\"), max_new_tokens=500))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
